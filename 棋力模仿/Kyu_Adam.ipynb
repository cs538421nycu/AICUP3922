{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9b1ed3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchsummary import summary\n",
    "from thop import profile\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc91074",
   "metadata": {},
   "source": [
    "# Rotate and Flip Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfc50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = 'abcdefghijklmnopqrs'\n",
    "def rotate90(move_list):\n",
    "    char_RowtoCol = 'abcdefghijklmnopqrs'\n",
    "    char_ColtoRow = 'srqponmlkjihgfedcba'\n",
    "    return_list = []\n",
    "    for chess in move_list:\n",
    "        return_list.append(chess[:2] + char_ColtoRow[char.find(chess[3])] + char_RowtoCol[char.find(chess[2])] + chess[4:])\n",
    "    return return_list\n",
    "\n",
    "def rotate180(move_list):\n",
    "    char_RowtoRow = 'srqponmlkjihgfedcba'\n",
    "    char_ColtoCol = 'srqponmlkjihgfedcba'\n",
    "    return_list = []\n",
    "    for chess in move_list:\n",
    "        return_list.append(chess[:2] + char_RowtoRow[char.find(chess[2])] + char_ColtoCol[char.find(chess[3])] + chess[4:])\n",
    "    return return_list\n",
    "\n",
    "def rotate270(move_list):\n",
    "    char_ColtoRow = 'abcdefghijklmnopqrs'\n",
    "    char_RowtoCol = 'srqponmlkjihgfedcba'\n",
    "    return_list = []\n",
    "    for chess in move_list:\n",
    "        return_list.append(chess[:2] + char_ColtoRow[char.find(chess[3])] + char_RowtoCol[char.find(chess[2])] + chess[4:])\n",
    "    return return_list\n",
    "\n",
    "def flip_up_down(move_list):\n",
    "    char_RowtoRow = 'srqponmlkjihgfedcba'\n",
    "    return_list = []\n",
    "    for chess in move_list:\n",
    "        return_list.append(chess[:2] + char_RowtoRow[char.find(chess[2])] + chess[3:])\n",
    "    return return_list\n",
    "\n",
    "def flip_rotate(move_list, type):\n",
    "    function = [rotate90, rotate180, rotate270, flip_up_down]\n",
    "    if type % 4 != 0:\n",
    "        move_list = function[type % 4 - 1](move_list)\n",
    "    if type // 4 != 0:\n",
    "        move_list = function[3](move_list)\n",
    "    return move_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd335be2",
   "metadata": {},
   "source": [
    "# Make DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_CSV(type):\n",
    "    df = open('./29_Training Dataset/Training Dataset/kyu_train.csv').read().splitlines()\n",
    "    color = [line.strip().split(',')[1] for line in df]\n",
    "    games = [i.split(',', 2)[-1] for i in df]\n",
    "    x = []\n",
    "    y = []\n",
    "    prediction_color = []\n",
    "\n",
    "    for idx, game in enumerate(tqdm(games)):\n",
    "        moves = game.split(',')\n",
    "        moves = flip_rotate(moves, type)\n",
    "        if color[idx] == 'B':\n",
    "            for count in range(2, len(moves), 2):\n",
    "                prediction_color.append(color[idx])\n",
    "                x.append((moves[:count]))\n",
    "                y.append((moves[count]))\n",
    "        else:\n",
    "            for count in range(1, len(moves), 2):\n",
    "                prediction_color.append(color[idx])\n",
    "                x.append((moves[:count]))\n",
    "                y.append((moves[count]))\n",
    "    print(\"Total data: \", len(y))\n",
    "    return x, y, prediction_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "dirR = [-1, -1, -1, 0, 0, 1, 1, 1, -2, -2, -2, -2, -2, -1, -1, 0, 0, 1, 1, 2, 2 ,2 ,2 ,2, -3, -3, -3, -3, -3, -3, -3\n",
    "       , -2, -2, -1, -1, 0, 0, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3]\n",
    "dirC = [-1, 0, 1, -1, 1, -1, 0, 1, -2, -1, 0, 1, 2, -2, 2, -2, 2, -2, 2, -2, -1, 0, 1, 2, -3, -2, -1, 0, 1, 2, 3, -3\n",
    "       , 3, -3, 3, -3, 3, -3, 3, -3, 3, -3, -2, -1, 0, 1, 2, 3]\n",
    "\n",
    "\n",
    "def prepare_input(moves, color):\n",
    "    x = np.zeros((19,19,21))\n",
    "    \n",
    "    lstn = 5\n",
    "    if(len(moves) < lstn):\n",
    "        lstn = len(moves)\n",
    "    \n",
    "    for i in range(1,lstn+1):\n",
    "        column = coordinates[moves[-i][2]]\n",
    "        row = coordinates[moves[-i][3]]\n",
    "        x[row, column, 21 - i] = 1\n",
    "        \n",
    "    \n",
    "    for move in moves:\n",
    "        colors = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if colors == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if colors == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "            \n",
    "    my_piece = x[:,:,0]\n",
    "    opt_piece = x[:,:,1]\n",
    "    \n",
    "    tmp_my_piece = np.empty((19,19))\n",
    "    tmp_my_piece[::, 0:-1] = my_piece[::, 1:]\n",
    "    tmp_my_piece[::, [-1]] = 0\n",
    "    x[:,:,4] += tmp_my_piece\n",
    "    \n",
    "    tmp_my_piece = np.empty((19,19))\n",
    "    tmp_my_piece[::, 1:] = my_piece[::, 0:-1]\n",
    "    tmp_my_piece[::, [0]] = 0\n",
    "    x[:,:,4] += tmp_my_piece\n",
    "    \n",
    "    tmp_my_piece = np.empty((19,19))\n",
    "    tmp_my_piece[0:-1, ::] = my_piece[1:, ::]\n",
    "    tmp_my_piece[[-1], ::] = 0\n",
    "    x[:,:,4] += tmp_my_piece\n",
    "    \n",
    "    tmp_my_piece = np.empty((19,19))\n",
    "    tmp_my_piece[1:, ::] = my_piece[0:-1, ::]\n",
    "    tmp_my_piece[[0], ::] = 0\n",
    "    x[:,:,4] += tmp_my_piece\n",
    "    \n",
    "    tmp_opt_piece = np.empty((19,19))\n",
    "    tmp_opt_piece[::, 0:-1] = opt_piece[::, 1:]\n",
    "    tmp_opt_piece[::, [-1]] = 0\n",
    "    x[:,:,9] += tmp_opt_piece\n",
    "    \n",
    "    tmp_opt_piece = np.empty((19,19))\n",
    "    tmp_opt_piece[::, 1:] = opt_piece[::, 0:-1]\n",
    "    tmp_opt_piece[::, [0]] = 0\n",
    "    x[:,:,9] += tmp_opt_piece\n",
    "    \n",
    "    tmp_opt_piece = np.empty((19,19))\n",
    "    tmp_opt_piece[0:-1, ::] = opt_piece[1:, ::]\n",
    "    tmp_opt_piece[[-1], ::] = 0\n",
    "    x[:,:,9] += tmp_opt_piece\n",
    "    \n",
    "    tmp_opt_piece = np.empty((19,19))\n",
    "    tmp_opt_piece[1:, ::] = opt_piece[0:-1, ::]\n",
    "    tmp_opt_piece[[0], ::] = 0\n",
    "    x[:,:,9] += tmp_opt_piece\n",
    "                        \n",
    "    x[:,:,3] = np.where(x[:,:,2] == 1, 0, 1)    \n",
    "        \n",
    "    x[:,:,5] = np.where(x[:,:,4] == 1, 1, 0)\n",
    "    x[:,:,6] = np.where(x[:,:,4] == 2, 1, 0)\n",
    "    x[:,:,7] = np.where(x[:,:,4] == 3, 1, 0)\n",
    "    x[:,:,8] = np.where(x[:,:,4] == 4, 1, 0)\n",
    "    x[:,:,4] = np.where(x[:,:,4] == 0, 1, 0)\n",
    "   \n",
    "    x[:,:,10] = np.where(x[:,:,9] == 1, 1, 0)\n",
    "    x[:,:,11] = np.where(x[:,:,9] == 2, 1, 0)\n",
    "    x[:,:,12] = np.where(x[:,:,9] == 3, 1, 0)\n",
    "    x[:,:,13] = np.where(x[:,:,9] == 4, 1, 0)\n",
    "    x[:,:,9] = np.where(x[:,:,9] == 0, 1, 0)\n",
    "        \n",
    "    x[:,:,15] = np.where(x[:,:,14] == 0, 1, 0)    \n",
    "        \n",
    "    x = np.transpose(x, (2, 0, 1))\n",
    "    if color == 'W':\n",
    "        x[[0, 1], :, :] = x[[1, 0], :, :]\n",
    "        x[[4, 9], :, :] = x[[9, 4], :, :]\n",
    "        x[[5, 10], :, :] = x[[10, 5], :, :]\n",
    "        x[[6, 11], :, :] = x[[11, 6], :, :]\n",
    "        x[[7, 12], :, :] = x[[12, 7], :, :]\n",
    "        x[[8, 13], :, :] = x[[13, 8], :, :]\n",
    "    return x\n",
    "    #x[0, :, :]放要預測的棋子, x[1, :, :]放對手的棋子, x[2, :, :]放有棋子的地方\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    index = column*19+row\n",
    "    return torch.tensor(index, dtype=torch.long)\n",
    "\n",
    "def ToImage(game):\n",
    "    game = np.array(game)\n",
    "    plt.imshow(game, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class game(Dataset):\n",
    "    def __init__(self, input, label, color):\n",
    "        self.input = input\n",
    "        self.label = label\n",
    "        self.color = color\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "    def __getitem__(self,idx):\n",
    "        moves = self.input[idx]\n",
    "        color = self.color[idx]\n",
    "        input = torch.from_numpy(np.float32(prepare_input(self.input[idx], self.color[idx])))\n",
    "        label = prepare_label(self.label[idx])\n",
    "        return {'input': input, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428897e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_dataloader(type):\n",
    "    x, y, prediction_color = Read_CSV(type)\n",
    "    dataset = game(x, y, prediction_color)\n",
    "    train_ds, val_ds = torch.utils.data.random_split(dataset, [int(len(y)*0.9), len(y) - int(len(y)*0.9)])\n",
    "    train_dl = DataLoader(train_ds, 32, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, 32, shuffle=False)\n",
    "    return train_dl, val_dl, train_ds, val_ds, x, y, prediction_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eaf6e4",
   "metadata": {},
   "source": [
    "# Residual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(InputBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x) + self.conv2(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class SqueezeExcitationBlock(nn.Module):\n",
    "    def __init__(self, in_planes, ratio):\n",
    "        super(SqueezeExcitationBlock, self).__init__()\n",
    "        self.dense1 = nn.Linear(in_planes, in_planes // ratio, bias=False)\n",
    "        self.dense2 = nn.Linear(in_planes // ratio, in_planes, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        se = F.adaptive_avg_pool2d((x), (1, 1))\n",
    "        se = se.reshape((se.shape[0], -1))\n",
    "        se = F.relu(self.dense1(se))\n",
    "        se = F.sigmoid(self.dense2(se))     \n",
    "        x = x * se.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
    "        return x\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, ratio=16):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.seblock = SqueezeExcitationBlock(out_planes, ratio)\n",
    "        self.shortcut = nn.Sequential()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.seblock(out)\n",
    "        return out\n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_planes=4, num_blocks=20, num_classes=361, ratio=16):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.layer1 = InputBlock(in_planes, out_planes=128, stride=1)\n",
    "        self.layer2 = self.make_layer(BasicBlock, 128, num_blocks, ratio)\n",
    "        self.layer3 = nn.Conv2d(128, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def make_layer(self, block, planes, num_blocks, ratio):\n",
    "        layers = []\n",
    "        for n in range(num_blocks):\n",
    "            layers.append(block(planes, planes, 1, ratio))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.flatten(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(in_planes=21, num_blocks=20, num_classes=361).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05279b81",
   "metadata": {},
   "source": [
    "# Testing Model Computational Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b6875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1, 21, 19, 19).cuda()\n",
    "\n",
    "model.eval()\n",
    "out = model(input)\n",
    "\n",
    "summary(model, input_size=(21, 19, 19))\n",
    "print(f'From input shape: {input.shape} to output shape: {out.shape}')\n",
    "\n",
    "\n",
    "macs, parm = profile(model, inputs=(input, ))\n",
    "print(f'FLOPS: {macs * 2 / 1e9} G, Params: {parm / 1e6} M.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfeb6b",
   "metadata": {},
   "source": [
    "# Optimizer、Scheduler、Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.000025)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.99, patience=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6552f2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculus_accuracy_top1(pro, label):\n",
    "    prediction = pro.argmax(dim=1)\n",
    "    correct_prediction = (prediction == label).float()\n",
    "    accuracy = torch.mean(correct_prediction) * 100\n",
    "    return accuracy.item()\n",
    "\n",
    "def calculus_accuracy_top5(pro, label):\n",
    "    top5_indices = pro.topk(5, dim=1)[1]\n",
    "    accuracy = 0\n",
    "    for i in range(5):\n",
    "        prediction = top5_indices[:, i].unsqueeze(1)\n",
    "        correct_prediction = (prediction == label.unsqueeze(1)).float()\n",
    "        accuracy += torch.mean(correct_prediction) * 100\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc985f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, device, val_dl):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    acc_top1 = 0\n",
    "    acc_top5 = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tqdm(val_dl)):\n",
    "            input = data['input'].to(device)\n",
    "            label = data['label'].to(device)\n",
    "            out = model(input)\n",
    "            val_loss += criterion(out, label)\n",
    "            acc_top1 += calculus_accuracy_top1(out, label)\n",
    "            acc_top5 += calculus_accuracy_top5(out, label)\n",
    "\n",
    "    val_loss /= len(val_dl)\n",
    "    acc_top1 /= len(val_dl)\n",
    "    acc_top5 /= len(val_dl)\n",
    "    print('\\nTest Set Average loss: {:.10f}'.format(val_loss))\n",
    "    logging.info('Test Set Average loss: {:.10f}'.format(val_loss))\n",
    "    print('The top1 accuracy of model in validation data is {:.4f}%'.format(acc_top1))\n",
    "    logging.info('The top1 accuracy of model in validation data is {:.4f}%'.format(acc_top1))\n",
    "    print('The top5 accuracy of model in validation data is {:.4f}%'.format(acc_top5))\n",
    "    logging.info('The top5 accuracy of model in validation data is {:.4f}%'.format(acc_top5))\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Kyu_Adam_Weight'\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "\n",
    "lrs = []\n",
    "train = []\n",
    "val = []\n",
    "def Train(epochs, model, device):\n",
    "    best_loss = float('inf')\n",
    "    logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG,\n",
    "                       handlers=[logging.FileHandler(\"Kyu_Adam.txt\"),logging.StreamHandler()])\n",
    "    logging.info(f'Start Training at {time.asctime()}')\n",
    "    logging.info('='*60)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print('Prepare DataLoader...')\n",
    "        train_dl, val_dl, train_ds, val_ds, x, y, prediction_color = make_dataloader(epoch-1)\n",
    "        model.train()\n",
    "        epoch_loss = 0.\n",
    "        for batch_idx, data in enumerate(tqdm(train_dl)):\n",
    "            input = data['input'].to(device)\n",
    "            label = data['label'].to(device)\n",
    "            lrs.append(optimizer.param_groups[0]['lr'])\n",
    "            optimizer.zero_grad()\n",
    "            out = model(input)\n",
    "            loss = criterion(out, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            epoch_loss += loss.item()\n",
    "        print('Train Epoch: {} Loss: {:.10f}'.format(epoch, epoch_loss/len(train_dl)))\n",
    "        logging.info('Train Epoch: {} Loss: {:.10f}'.format(epoch, epoch_loss/len(train_dl)))\n",
    "        train_loss = epoch_loss/len(train_dl)\n",
    "        train.append(train_loss)\n",
    "        val_loss = Test(model, device, val_dl)\n",
    "        val.append(val_loss)\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            print(\"Saving checkpoint...\")\n",
    "            state = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'best_loss': best_loss }\n",
    "            torch.save(state, './checkpoint_kyu_adam.pth')\n",
    "\n",
    "        state = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'best_loss': best_loss }\n",
    "        torch.save(state, f'{save_path}/checkpoint_Kyu_Adam_{epoch}.pth')\n",
    "        logging.info(f'This epoch is end {time.asctime()}')\n",
    "        logging.info('='*60)\n",
    "            \n",
    "        del train_dl, val_dl, train_ds, val_ds, x, y, prediction_color\n",
    "    print(f'Best loss in this training process : {best_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc0557",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Train(13, model, 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c80fe",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lrs(lrs):\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.')\n",
    "\n",
    "plot_lrs(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2006f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train, val):\n",
    "    plt.plot(train, '-bx')\n",
    "    plt.plot(val, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "\n",
    "plot_losses(train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5c3ee",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d9845",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = './checkpoint_kyu_adam.pth'\n",
    "checkpoint = torch.load(weight_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56819de",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143dfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_char(number):\n",
    "    number_1, number_2 = divmod(number, 19)\n",
    "    return chartonumbers[number_1] + chartonumbers[number_2]\n",
    "\n",
    "def top_5_preds_with_chars(predictions):\n",
    "    resulting_preds_numbers = [np.flip(np.argsort(prediction)[-5:]) for prediction in predictions]\n",
    "    resulting_preds_chars = np.vectorize(number_to_char)(resulting_preds_numbers)\n",
    "    return resulting_preds_chars\n",
    "\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5579890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./29_Public Testing Dataset_Public Submission Template_v2/29_Public Testing Dataset_v2/kyu_test_public.csv').read().splitlines()\n",
    "color = [line.strip().split(',')[1] for line in df]\n",
    "games_id = [i.split(',',2)[0] for i in df]\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "\n",
    "x_testing = []\n",
    "\n",
    "for idx, game in enumerate(games):\n",
    "    moves_list = game.split(',')\n",
    "    x_testing.append(prepare_input(moves_list, color[idx]))\n",
    "\n",
    "with open('./upload_Kyu_Adam.csv', 'a+') as f:\n",
    "    for idx, test_data in enumerate(tqdm(x_testing)):\n",
    "        test_data = torch.from_numpy(np.array(test_data)).float().to('cuda')\n",
    "        test_data = test_data.reshape(1, test_data.shape[0], 19, 19)\n",
    "        predictions = model(test_data).to('cpu').detach().numpy()\n",
    "        prediction_chars = top_5_preds_with_chars(predictions)\n",
    "        answer_row = games_id[idx] + ',' + ','.join(prediction_chars[0]) + '\\n'\n",
    "        f.write(answer_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348febb",
   "metadata": {},
   "source": [
    "# Private Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./29_Private Testing Dataset_Public and Private Submission Template_v2/29_Private Testing Dataset_v2/kyu_test_private.csv').read().splitlines()\n",
    "color = [line.strip().split(',')[1] for line in df]\n",
    "games_id = [i.split(',',2)[0] for i in df]\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "\n",
    "x_testing = []\n",
    "\n",
    "for idx, game in enumerate(games):\n",
    "    moves_list = game.split(',')\n",
    "    x_testing.append(prepare_input(moves_list, color[idx]))\n",
    "\n",
    "with open('./upload_Kyu_Adam.csv', 'a+') as f:\n",
    "    for idx, test_data in enumerate(tqdm(x_testing)):\n",
    "        \n",
    "        test_data = torch.from_numpy(np.array(test_data)).float().to('cuda')\n",
    "        test_data = test_data.reshape(1, test_data.shape[0], 19, 19)\n",
    "        predictions = model(test_data).to('cpu').detach().numpy()\n",
    "        prediction_chars = top_5_preds_with_chars(predictions)\n",
    "        answer_row = games_id[idx] + ',' + ','.join(prediction_chars[0]) + '\\n'\n",
    "        f.write(answer_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
